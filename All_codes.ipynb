{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dff579-1bbe-49d4-b499-ccaacb3f3ffa",
   "metadata": {},
   "source": [
    "# YOLO11 Codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2ce7f9-725a-4838-940f-201b4f16de95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516182f8-3f5d-46f8-9e63-0a6973c3eb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123440d1-37bc-44aa-b6e8-ca7ee8bd8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854536a9-bd70-4931-939a-794e6970b868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 26 12:04:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8              1W /   65W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     10668    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A     13044    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A     32544      C   ...rograms\\Python\\Python312\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df4378-2630-4053-95d5-159d527f2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=\"E:/project_jupyter/main_backup/data_main.yml\",  # path to dataset YAML\n",
    "    epochs=100,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=0,\n",
    "    batch = 12,\n",
    "    plots=True # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51163b70-992a-4e59-9f09-5fa46efb1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov11n.pt\")\n",
    "\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=\"E:/project_jupyter/main_backup/data_main.yml\",  # path to dataset YAML\n",
    "    epochs=200,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=0,\n",
    "    batch = 12,\n",
    "    plots=True # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353bb54-2af7-4fbf-9506-65aa64b9e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO(r\"C:\\Users\\debas\\Downloads\\best (2).pt\")  # Replace 'best.pt' with your trained model's path if different\n",
    "\n",
    "# Load the video\n",
    "video_path = r\"C:\\Users\\debas\\Downloads\\new\\fighting.mp4\"  # Replace with your MP4 video file\n",
    "output_path = \"output_videos46.mp4\" # Path to save the output video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec for MP4\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Visualize predictions on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # (Optional) Display the frame with detections in real-time\n",
    "    display_frame = cv2.resize(annotated_frame, None, fx=0.5, fy=0.5)  # Adjust fx, fy as needed\n",
    "    cv2.imshow(\"YOLO11 Inference\", display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c609708-8ef0-46aa-904c-d5ca60c9a45f",
   "metadata": {},
   "source": [
    "# FER codes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e24736-d334-45b6-8e29-275d15f3121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fer import FER\n",
    "\n",
    "# Initialize webcam and FER detector\n",
    "detector = FER(mtcnn=True)  # mtcnn=True gives better face detection\n",
    "cap = cv2.VideoCapture(0)   # 0 is the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to speed up detection\n",
    "    resized_frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    # Detect emotions in the frame\n",
    "    results = detector.detect_emotions(resized_frame)\n",
    "\n",
    "    # Draw boxes and labels\n",
    "    for result in results:\n",
    "        (x, y, w, h) = result[\"box\"]\n",
    "        emotions = result[\"emotions\"]\n",
    "        max_emotion = max(emotions, key=emotions.get)\n",
    "\n",
    "        cv2.rectangle(resized_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(resized_frame, max_emotion, (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"FER Webcam\", resized_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f8e0b-b3ed-47e6-b722-69e6671a3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from fer import FER\n",
    "\n",
    "# Output directory to save .pt files\n",
    "output_dir = \"fer_features\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize FER detector\n",
    "detector = FER(mtcnn=True)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 100  # Change this to capture more or fewer frames\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    resized = cv2.resize(frame, (640, 480))\n",
    "    results = detector.detect_emotions(resized)\n",
    "\n",
    "    if results:\n",
    "        emotions = results[0][\"emotions\"]  # first face\n",
    "        emotion_tensor = torch.tensor([emotions[k] for k in sorted(emotions.keys())])\n",
    "\n",
    "        # Save tensor\n",
    "        torch.save(emotion_tensor, os.path.join(output_dir, f\"frame_{frame_count:04d}.pt\"))\n",
    "\n",
    "        print(f\"Saved frame_{frame_count:04d}.pt --> {emotions}\")\n",
    "\n",
    "    frame_count += 1\n",
    "    cv2.imshow(\"Capturing FER\", resized)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860ed4f-535a-4d06-8c2b-dcab97cb6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Settings\n",
    "feature_dir = r\"E:/fer_features\"\n",
    "csv_path = os.path.join(feature_dir, \"fer_labels.csv\")\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "# ✅ Dataset\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, csv_file, feature_dir, label_encoder):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.samples = df.values\n",
    "        self.feature_dir = feature_dir\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename, label = self.samples[idx]\n",
    "        tensor = torch.load(os.path.join(self.feature_dir, filename))\n",
    "        tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "\n",
    "        if isinstance(label, str):\n",
    "            label_idx = self.label_encoder.transform([label])[0]\n",
    "        else:\n",
    "            label_idx = label  # already encoded\n",
    "\n",
    "        return tensor, label_idx\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Prepare Data\n",
    "df = pd.read_csv(csv_path)\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"train_tmp.csv\", index=False)\n",
    "val_df.to_csv(\"val_tmp.csv\", index=False)\n",
    "\n",
    "train_dataset = FERDataset(\"train_tmp.csv\", feature_dir, le)\n",
    "val_dataset = FERDataset(\"val_tmp.csv\", feature_dir, le)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# ✅ Simple MLP Model\n",
    "class FERClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = FERClassifier(num_classes=len(le.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# ✅ Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "# ✅ Validation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        out = model(x)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "print(f\"Validation Accuracy: {correct / total:.2%}\")\n",
    "\n",
    "# ✅ Save model and encoder\n",
    "torch.save(model.state_dict(), \"fer_behavior_classifier.pt\")\n",
    "import pickle\n",
    "with open(\"fer_label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d834c0c-43a5-43c5-b7d0-3831ac12930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check both CSVs\n",
    "print(pd.read_csv(\"train_tmp.csv\").head(10))\n",
    "print(pd.read_csv(\"val_tmp.csv\").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f04f7-90f0-4d3d-abd0-af1603ee34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_dir = r\"E:/fer_features\"\n",
    "csv_path = os.path.join(feature_dir, \"fer_labels.csv\")\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "# Dataset\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, csv_file, feature_dir):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.samples = df.values\n",
    "        self.feature_dir = feature_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename, label = self.samples[idx]\n",
    "        tensor = torch.load(os.path.join(self.feature_dir, filename))\n",
    "        tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "        label_idx = int(label)  # ✅ fixed and correctly indented\n",
    "        return tensor, label_idx\n",
    "\n",
    "# Prepare data\n",
    "df = pd.read_csv(csv_path)\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"train_tmp.csv\", index=False)\n",
    "val_df.to_csv(\"val_tmp.csv\", index=False)\n",
    "\n",
    "# Loaders\n",
    "train_dataset = FERDataset(\"train_tmp.csv\", feature_dir)\n",
    "val_dataset = FERDataset(\"val_tmp.csv\", feature_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Model\n",
    "class FERClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = FERClassifier(num_classes=len(le.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Validate\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        out = model(x)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "print(f\"Validation Accuracy: {correct / total:.2%}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"fer_behavior_classifier.pt\")\n",
    "import pickle\n",
    "with open(\"fer_label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36a9c5-5b62-4e52-8e2e-70f804d50890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from fer import FER\n",
    "\n",
    "# === PATHS ===\n",
    "video_path = r\"E:\\env1gputest\\our_vids\\fighting_nil_deb.mp4\"  # Replace with your video path\n",
    "yolo_model_path = r\"E:\\runs\\detect\\train28\\weights\\best.pt\"\n",
    "fer_model_path = r\"E:\\fer_behavior_classifier.pt\"\n",
    "label_encoder_path = r\"E:\\fer_label_encoder.pkl\"\n",
    "\n",
    "# === LOAD MODELS ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load YOLOv11 model\n",
    "yolo_model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "# Load FER feature extractor\n",
    "fer_detector = FER(mtcnn=True)  # mtcnn gives better face extraction\n",
    "\n",
    "# Load behavior classifier\n",
    "class FERClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(7, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "with open(label_encoder_path, 'rb') as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "model = FERClassifier(num_classes=len(le.classes_))\n",
    "model.load_state_dict(torch.load(fer_model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === INFERENCE ON VIDEO ===\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Step 1: Detect person using YOLO\n",
    "    results = yolo_model(frame)\n",
    "    for box in results[0].boxes.data:\n",
    "        cls_id = int(box[5].item())\n",
    "        conf = box[4].item()\n",
    "        x1, y1, x2, y2 = map(int, box[:4])\n",
    "\n",
    "        # Skip if not person class (you can adjust if needed)\n",
    "        if cls_id != 0 or conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        person_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Step 2: FER Emotion extraction\n",
    "        emotion_probs = fer_detector.detect_emotions(person_crop)\n",
    "        if emotion_probs:\n",
    "            # Grab 1st face\n",
    "            emotions = emotion_probs[0][\"emotions\"]\n",
    "            feature_vector = torch.tensor(list(emotions.values()), dtype=torch.float32).to(device)\n",
    "\n",
    "            # Step 3: Behavior classification\n",
    "            with torch.no_grad():\n",
    "                output = model(feature_vector.unsqueeze(0))\n",
    "                pred = output.argmax(dim=1).item()\n",
    "                label = le.inverse_transform([pred])[0]\n",
    "\n",
    "            # Step 4: Draw box and label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Behavior Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a42a09",
   "metadata": {},
   "source": [
    "# Video Classifier Using LSTM(RNN) and CNN\n",
    "#!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b4b70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fight', 'normal', 'theft']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Make sure to type the path directly without any accidental hidden characters\n",
    "dataset_path = os.listdir(r'E:\\debs_proj\\trial_dataset\\train')\n",
    "\n",
    "label_types = os.listdir(r'E:\\debs_proj\\trial_dataset\\train')\n",
    "print(label_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f06c4",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e00542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tag                                    video_name\n",
      "0  fight  E:\\debs_proj\\trial_dataset\\train/fight/0.mp4\n",
      "1  fight  E:\\debs_proj\\trial_dataset\\train/fight/1.mp4\n",
      "2  fight  E:\\debs_proj\\trial_dataset\\train/fight/2.mp4\n",
      "3  fight  E:\\debs_proj\\trial_dataset\\train/fight/3.mp4\n",
      "4  fight  E:\\debs_proj\\trial_dataset\\train/fight/4.mp4\n",
      "      tag                                         video_name\n",
      "29  theft  E:\\debs_proj\\trial_dataset\\train/theft/Shoplif...\n",
      "30  theft  E:\\debs_proj\\trial_dataset\\train/theft/Stealin...\n",
      "31  theft  E:\\debs_proj\\trial_dataset\\train/theft/Stealin...\n",
      "32  theft  E:\\debs_proj\\trial_dataset\\train/theft/Stealin...\n",
      "33  theft  E:\\debs_proj\\trial_dataset\\train/theft/Stealin...\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir(r'E:\\debs_proj\\trial_dataset\\train' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str(r'E:\\debs_proj\\trial_dataset\\train' + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ac79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('train_trial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0897c2",
   "metadata": {},
   "source": [
    "# Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413b31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fight', 'normal', 'theft']\n",
      "Types of activities found:  3\n",
      "      tag                                         video_name\n",
      "0   fight        E:\\debs_proj\\trial_dataset\\test/fight/0.mp4\n",
      "1   fight        E:\\debs_proj\\trial_dataset\\test/fight/1.mp4\n",
      "2   fight        E:\\debs_proj\\trial_dataset\\test/fight/2.mp4\n",
      "3  normal  E:\\debs_proj\\trial_dataset\\test/normal/Clappin...\n",
      "4  normal  E:\\debs_proj\\trial_dataset\\test/normal/Meet an...\n",
      "       tag                                         video_name\n",
      "8   normal  E:\\debs_proj\\trial_dataset\\test/normal/Walking...\n",
      "9   normal  E:\\debs_proj\\trial_dataset\\test/normal/Walking...\n",
      "10   theft  E:\\debs_proj\\trial_dataset\\test/theft/rapidsav...\n",
      "11   theft  E:\\debs_proj\\trial_dataset\\test/theft/Shoplift...\n",
      "12   theft  E:\\debs_proj\\trial_dataset\\test/theft/Stealing...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir(r'E:\\debs_proj\\trial_dataset\\test')\n",
    "print(dataset_path)\n",
    "\n",
    "room_types = os.listdir(r'E:\\debs_proj\\trial_dataset\\test')\n",
    "print(\"Types of activities found: \", len(dataset_path))\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir(r'E:\\debs_proj\\trial_dataset\\test' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str(r'E:\\debs_proj\\trial_dataset\\test' + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('test_trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45fb7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\ECE\\AppData\\Local\\Temp\\pip-req-build-ryaq4exe'\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\ece\\appdata\\local\\temp\\pip-req-build-ryaq4exe\n",
      "  Resolved https://github.com/tensorflow/docs to commit a8576cef38b7182e6228d7aafca8ef51754ab9e8\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: astor in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (0.8.1)\n",
      "Requirement already satisfied: absl-py in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (2.2.2)\n",
      "Requirement already satisfied: jinja2 in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (3.1.3)\n",
      "Requirement already satisfied: nbformat in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (5.10.4)\n",
      "Requirement already satisfied: protobuf>=3.12 in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (3.19.6)\n",
      "Requirement already satisfied: pyyaml in e:\\debs_proj\\lib\\site-packages (from tensorflow-docs==2025.3.6.10029) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\debs_proj\\lib\\site-packages (from jinja2->tensorflow-docs==2025.3.6.10029) (2.1.5)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in e:\\debs_proj\\lib\\site-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (2.21.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in e:\\debs_proj\\lib\\site-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (5.7.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in e:\\debs_proj\\lib\\site-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (4.23.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in e:\\debs_proj\\lib\\site-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (5.14.3)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\debs_proj\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (0.23.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\debs_proj\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\debs_proj\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (0.36.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\debs_proj\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (25.3.0)\n",
      "Requirement already satisfied: pywin32>=300 in e:\\debs_proj\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2025.3.6.10029) (310)\n",
      "Requirement already satisfied: platformdirs>=2.5 in e:\\debs_proj\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2025.3.6.10029) (4.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in e:\\debs_proj\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918d9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4fed40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf44bb",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b716cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 34\n",
      "Total videos for testing: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/theft/Shoplif...</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Standi...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Walkin...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/theft/Shoplif...</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/fight/Assault...</td>\n",
       "      <td>fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Clappi...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Sittin...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Standi...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Meet a...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>E:\\debs_proj\\trial_dataset\\train/normal/Walkin...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         video_name     tag\n",
       "29          29  E:\\debs_proj\\trial_dataset\\train/theft/Shoplif...   theft\n",
       "17          17  E:\\debs_proj\\trial_dataset\\train/normal/Standi...  normal\n",
       "21          21  E:\\debs_proj\\trial_dataset\\train/normal/Walkin...  normal\n",
       "28          28  E:\\debs_proj\\trial_dataset\\train/theft/Shoplif...   theft\n",
       "7            7  E:\\debs_proj\\trial_dataset\\train/fight/Assault...   fight\n",
       "10          10  E:\\debs_proj\\trial_dataset\\train/normal/Clappi...  normal\n",
       "16          16  E:\\debs_proj\\trial_dataset\\train/normal/Sittin...  normal\n",
       "19          19  E:\\debs_proj\\trial_dataset\\train/normal/Standi...  normal\n",
       "14          14  E:\\debs_proj\\trial_dataset\\train/normal/Meet a...  normal\n",
       "24          24  E:\\debs_proj\\trial_dataset\\train/normal/Walkin...  normal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_trial.csv\")\n",
    "test_df = pd.read_csv(\"test_trial.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c182a",
   "metadata": {},
   "source": [
    "# Feed the videos to a network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd68b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two methods are taken from this tutorial:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243c6ee",
   "metadata": {},
   "source": [
    "   ### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388c0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ca626",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "StringLookup layer encode the class labels as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "801339d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fight', 'normal', 'theft']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4ac85",
   "metadata": {},
   "source": [
    "Finally, we can put all the pieces together to create our data processing utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18db18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0].shape)\n",
    "#train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76216366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11befa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (34, 20, 2048)\n",
      "Frame masks in train set: (34, 20)\n",
      "train_labels in train set: (34, 1)\n",
      "test_labels in train set: (13, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    \n",
    "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
    "    labels = df[\"tag\"].values\n",
    "    \n",
    "    #convert classlabels to label encoding\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "               temp_frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :], verbose=0)\n",
    "\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")\n",
    "\n",
    "# MAX_SEQ_LENGTH = 20, NUM_FEATURES = 2048. We have defined this above under hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68cc467a-8757-42f9-9738-b88527a67ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (34, 20, 2048)\n",
      "Frame masks in train set: (34, 20)\n",
      "train_labels in train set: (34, 1)\n",
      "test_labels in train set: (13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e0827",
   "metadata": {},
   "source": [
    "# The sequence model\n",
    "Now, we can feed this data to a sequence model consisting of recurrent layers like GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7382f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1616 - accuracy: 0.4348\n",
      "Epoch 1: val_loss improved from inf to 1.07378, saving model to ./tmp\\video_classifier\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.1616 - accuracy: 0.4348 - val_loss: 1.0738 - val_accuracy: 0.2727\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.4783\n",
      "Epoch 2: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9987 - accuracy: 0.4783 - val_loss: 1.0992 - val_accuracy: 0.3636\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0150 - accuracy: 0.5217\n",
      "Epoch 3: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0150 - accuracy: 0.5217 - val_loss: 1.1462 - val_accuracy: 0.3636\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8585 - accuracy: 0.5652\n",
      "Epoch 4: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8585 - accuracy: 0.5652 - val_loss: 1.1452 - val_accuracy: 0.3636\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.5217\n",
      "Epoch 5: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8913 - accuracy: 0.5217 - val_loss: 1.1723 - val_accuracy: 0.3636\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8175 - accuracy: 0.5652\n",
      "Epoch 6: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8175 - accuracy: 0.5652 - val_loss: 1.1887 - val_accuracy: 0.3636\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.6087\n",
      "Epoch 7: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7332 - accuracy: 0.6087 - val_loss: 1.1970 - val_accuracy: 0.3636\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.5652\n",
      "Epoch 8: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7743 - accuracy: 0.5652 - val_loss: 1.2000 - val_accuracy: 0.3636\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7572 - accuracy: 0.5652\n",
      "Epoch 9: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7572 - accuracy: 0.5652 - val_loss: 1.1792 - val_accuracy: 0.3636\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7410 - accuracy: 0.6087\n",
      "Epoch 10: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7410 - accuracy: 0.6087 - val_loss: 1.1484 - val_accuracy: 0.3636\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.5217\n",
      "Epoch 11: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8471 - accuracy: 0.5217 - val_loss: 1.1041 - val_accuracy: 0.3636\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7591 - accuracy: 0.6087\n",
      "Epoch 12: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7591 - accuracy: 0.6087 - val_loss: 1.1050 - val_accuracy: 0.3636\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.6522\n",
      "Epoch 13: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7313 - accuracy: 0.6522 - val_loss: 1.1062 - val_accuracy: 0.3636\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.6087\n",
      "Epoch 14: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6994 - accuracy: 0.6087 - val_loss: 1.1220 - val_accuracy: 0.3636\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7567 - accuracy: 0.6522\n",
      "Epoch 15: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7567 - accuracy: 0.6522 - val_loss: 1.1324 - val_accuracy: 0.3636\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.5652\n",
      "Epoch 16: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6979 - accuracy: 0.5652 - val_loss: 1.1347 - val_accuracy: 0.3636\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.6087\n",
      "Epoch 17: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6786 - accuracy: 0.6087 - val_loss: 1.1352 - val_accuracy: 0.3636\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.6522\n",
      "Epoch 18: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6064 - accuracy: 0.6522 - val_loss: 1.1275 - val_accuracy: 0.3636\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7778 - accuracy: 0.5652\n",
      "Epoch 19: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7778 - accuracy: 0.5652 - val_loss: 1.1278 - val_accuracy: 0.3636\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.5652\n",
      "Epoch 20: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6731 - accuracy: 0.5652 - val_loss: 1.1415 - val_accuracy: 0.3636\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.5652\n",
      "Epoch 21: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6436 - accuracy: 0.5652 - val_loss: 1.1699 - val_accuracy: 0.3636\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7244 - accuracy: 0.5652\n",
      "Epoch 22: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7244 - accuracy: 0.5652 - val_loss: 1.1898 - val_accuracy: 0.3636\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.5652\n",
      "Epoch 23: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6385 - accuracy: 0.5652 - val_loss: 1.2226 - val_accuracy: 0.3636\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.5652\n",
      "Epoch 24: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6314 - accuracy: 0.5652 - val_loss: 1.2506 - val_accuracy: 0.3636\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.6087\n",
      "Epoch 25: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - accuracy: 0.6087 - val_loss: 1.2447 - val_accuracy: 0.3636\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.5652\n",
      "Epoch 26: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6046 - accuracy: 0.5652 - val_loss: 1.2543 - val_accuracy: 0.3636\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.6087\n",
      "Epoch 27: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5981 - accuracy: 0.6087 - val_loss: 1.2514 - val_accuracy: 0.3636\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.5652\n",
      "Epoch 28: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5941 - accuracy: 0.5652 - val_loss: 1.2218 - val_accuracy: 0.3636\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.6522\n",
      "Epoch 29: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6096 - accuracy: 0.6522 - val_loss: 1.1841 - val_accuracy: 0.3636\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.6087\n",
      "Epoch 30: val_loss did not improve from 1.07378\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5910 - accuracy: 0.6087 - val_loss: 1.1492 - val_accuracy: 0.3636\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9551 - accuracy: 0.5385\n",
      "Test accuracy: 53.85%\n"
     ]
    }
   ],
   "source": [
    "# Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 30\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f1681",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "846a5956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: E:\\debs_proj\\trial_dataset\\test/normal/Clapping (1).mp4\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "  normal: 42.06%\n",
      "  theft: 29.91%\n",
      "  fight: 28.03%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6309d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
       "        <source src=\"E:/debs_proj/trial_dataset/test/fight/1.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
    "        <source src=\"E:/debs_proj/trial_dataset/test/fight/1.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6150d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"E:/debs_proj/trial_dataset/test/fight/1.mp4\"\n",
    "frames = load_video(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b16e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048\n",
    "video_length = frames.shape[0]\n",
    "length = min(video_length, MAX_SEQ_LENGTH)\n",
    "\n",
    "frame_mask = np.zeros((1, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "frame_features = np.zeros((1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "for i in range(length):\n",
    "    frame_features[0, i, :] = feature_extractor.predict(frames[None, i], verbose=0)\n",
    "\n",
    "frame_mask[0, :length] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad15f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = sequence_model.predict([frame_features, frame_mask])\n",
    "predicted_class = np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e431c46a-1b6f-4815-90ec-2ca337a3c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted action: normal\n"
     ]
    }
   ],
   "source": [
    "predicted_label = label_processor.get_vocabulary()[predicted_class[0]]\n",
    "print(f\"Predicted action: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c935e-131e-4b1f-b5ac-3338f0f4ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'classifier.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5939e3d-be78-405f-bce7-46911e9149e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/your-repo/yolo-v12\n",
    "cd yolo-v12\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe78e9-e310-456e-95a1-103346c6a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained or custom trained model\n",
    "yolo_model = YOLO(\"yolov12.pt\")  # or your own trained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f172a6-0653-4340-863b-32d9be7d31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load both models\n",
    "classifier = YourModelClass()\n",
    "classifier.load_state_dict(torch.load('classifier.pth'))\n",
    "classifier.eval()\n",
    "\n",
    "yolo = YOLO('yolov12.pt')\n",
    "\n",
    "# Preprocessing for classifier\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture(r\"E:\\debs_proj\\dataset_CNN_LSTM_method\\train\\fighting\\2.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo(frame)\n",
    "\n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert to PIL and preprocess\n",
    "        roi_tensor = transform(Image.fromarray(roi)).unsqueeze(0)\n",
    "\n",
    "        # Classify the cropped ROI\n",
    "        with torch.no_grad():\n",
    "            output = classifier(roi_tensor)\n",
    "            pred_class = output.argmax(dim=1).item()\n",
    "            label = class_names[pred_class]\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Result\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357904b4-083e-45ea-82aa-6c87e7944b50",
   "metadata": {},
   "source": [
    "# Telegram Bot Alert system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4450deb-d697-4132-8173-121b426d712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': [{'update_id': 588057992, 'my_chat_member': {'chat': {'id': -1002594728756, 'title': 'final_proj', 'type': 'supergroup'}, 'from': {'id': 1389732200, 'is_bot': False, 'first_name': 'Debashish', 'last_name': 'Kashyap', 'language_code': 'en'}, 'date': 1750862758, 'old_chat_member': {'user': {'id': 7494981174, 'is_bot': True, 'first_name': 'Hi', 'username': 'Rio56664_bot'}, 'status': 'member'}, 'new_chat_member': {'user': {'id': 7494981174, 'is_bot': True, 'first_name': 'Hi', 'username': 'Rio56664_bot'}, 'status': 'administrator', 'can_be_edited': False, 'can_manage_chat': True, 'can_change_info': True, 'can_delete_messages': True, 'can_invite_users': True, 'can_restrict_members': True, 'can_pin_messages': True, 'can_manage_topics': True, 'can_promote_members': False, 'can_manage_video_chats': True, 'can_post_stories': True, 'can_edit_stories': True, 'can_delete_stories': True, 'is_anonymous': False, 'can_manage_voice_chats': True}}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BOT_TOKEN = \"7494981174:AAF-BEpPZaRMSnPCAnmfzHTTTHvL31Eoto0\"\n",
    "\n",
    "response = requests.get(f\"https://api.telegram.org/bot{BOT_TOKEN}/getUpdates\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d309e39-2c5e-43ab-b73b-58548fe5e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'message_id': 46, 'from': {'id': 7494981174, 'is_bot': True, 'first_name': 'Hi', 'username': 'Rio56664_bot'}, 'chat': {'id': -1002594728756, 'title': 'final_proj', 'type': 'supergroup'}, 'date': 1750921572, 'text': '🔔 Test from Rio56664_bot'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BOT_TOKEN = '7494981174:AAF-BEpPZaRMSnPCAnmfzHTTTHvL31Eoto0'\n",
    "CHAT_ID = '-1002594728756'\n",
    "message = \"🔔 Test from Rio56664_bot\"\n",
    "\n",
    "url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
    "r = requests.post(url, data={\"chat_id\": CHAT_ID, \"text\": message})\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4a5e4e8-9895-4381-8940-980ae2d17239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x512 1 normal, 25.5ms\n",
      "Speed: 4.9ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 27.4ms\n",
      "Speed: 2.1ms preprocess, 27.4ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 16.1ms\n",
      "Speed: 1.8ms preprocess, 16.1ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 12.7ms\n",
      "Speed: 3.5ms preprocess, 12.7ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 23.1ms\n",
      "Speed: 1.1ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 25.9ms\n",
      "Speed: 7.0ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 17.6ms\n",
      "Speed: 6.0ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 24.2ms\n",
      "Speed: 0.0ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 27.9ms\n",
      "Speed: 0.0ms preprocess, 27.9ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 16.5ms\n",
      "Speed: 8.3ms preprocess, 16.5ms inference, 4.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 24.5ms\n",
      "Speed: 0.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 4.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.6ms\n",
      "Speed: 2.5ms preprocess, 20.6ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 18.6ms\n",
      "Speed: 0.0ms preprocess, 18.6ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 27.5ms\n",
      "Speed: 0.0ms preprocess, 27.5ms inference, 4.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 25.6ms\n",
      "Speed: 0.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.0ms\n",
      "Speed: 5.5ms preprocess, 20.0ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 10.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 22.4ms\n",
      "Speed: 0.0ms preprocess, 22.4ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 36.4ms\n",
      "Speed: 0.0ms preprocess, 36.4ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 18.5ms\n",
      "Speed: 2.6ms preprocess, 18.5ms inference, 5.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 19.8ms\n",
      "Speed: 3.1ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 25.4ms\n",
      "Speed: 3.1ms preprocess, 25.4ms inference, 4.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 28.3ms\n",
      "Speed: 0.0ms preprocess, 28.3ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 4.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 10.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 19.2ms\n",
      "Speed: 2.5ms preprocess, 19.2ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.6ms\n",
      "Speed: 3.1ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 21.3ms\n",
      "Speed: 7.0ms preprocess, 21.3ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 21.0ms\n",
      "Speed: 3.6ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 24.8ms\n",
      "Speed: 4.8ms preprocess, 24.8ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 22.6ms\n",
      "Speed: 9.5ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 14.2ms\n",
      "Speed: 1.5ms preprocess, 14.2ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 22.3ms\n",
      "Speed: 1.1ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 17.9ms\n",
      "Speed: 2.1ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 20.1ms\n",
      "Speed: 2.0ms preprocess, 20.1ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 50.6ms\n",
      "Speed: 0.0ms preprocess, 50.6ms inference, 11.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 120.0ms\n",
      "Speed: 14.3ms preprocess, 120.0ms inference, 7.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 31.9ms\n",
      "Speed: 3.5ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 24.1ms\n",
      "Speed: 6.1ms preprocess, 24.1ms inference, 8.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 normal, 40.6ms\n",
      "Speed: 0.0ms preprocess, 40.6ms inference, 11.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 2 normals, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 2 normals, 17.6ms\n",
      "Speed: 8.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 2 normals, 20.1ms\n",
      "Speed: 5.3ms preprocess, 20.1ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 1 vandalism, 26.7ms\n",
      "Speed: 3.1ms preprocess, 26.7ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connection.py:741\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 741\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connection.py:920\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    918\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 920\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\ssl_.py:460\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    458\u001b[0m context\u001b[38;5;241m.\u001b[39mset_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[1;32m--> 460\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\ssl_.py:504\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1319\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connection.py:741\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 741\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\connection.py:920\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    918\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 920\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\ssl_.py:460\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    458\u001b[0m context\u001b[38;5;241m.\u001b[39mset_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[1;32m--> 460\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\urllib3\\util\\ssl_.py:504\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1319\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(image_path, annotated_frame)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Send alert\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[43msend_telegram_alert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚨 ALERT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m detected with confidence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Alert once per suspicious frame to avoid spam\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 24\u001b[0m, in \u001b[0;36msend_telegram_alert\u001b[1;34m(image_path, label)\u001b[0m\n\u001b[0;32m     22\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Suspicious activity detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m msg_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.telegram.org/bot\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBOT_TOKEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sendMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHAT_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Send image\u001b[39;00m\n\u001b[0;32m     27\u001b[0m img_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.telegram.org/bot\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBOT_TOKEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sendPhoto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mE:\\env1gputest\\Lib\\site-packages\\requests\\adapters.py:682\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    686\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "BOT_TOKEN = '7494981174:AAF-BEpPZaRMSnPCAnmfzHTTTHvL31Eoto0'\n",
    "CHAT_ID = '-1002594728756'  # Group chat ID\n",
    "VIDEO_PATH = r\"C:\\Users\\debas\\Downloads\\CAUGHT ON CAMERA_ Austin City Hall vandalized (online-video-cutter.com).mp4\"\n",
    "SUSPICIOUS_CLASSES = ['theft', 'violence', 'vandalism']  # Class names to trigger alert\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = YOLO(r\"E:\\runs\\train45-20250614T153104Z-1-001\\train45\\weights\\best.pt\")  # Your trained YOLOv11s model\n",
    "\n",
    "# === LOAD VIDEO ===\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# === SEND ALERT TO TELEGRAM ===\n",
    "def send_telegram_alert(image_path, label):\n",
    "    # Send text message\n",
    "    message = f\"⚠️ Suspicious activity detected: {label.upper()}\"\n",
    "    msg_url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
    "    requests.post(msg_url, data={\"chat_id\": CHAT_ID, \"text\": message})\n",
    "\n",
    "    # Send image\n",
    "    img_url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto\"\n",
    "    with open(image_path, \"rb\") as photo:\n",
    "        requests.post(img_url, data={\"chat_id\": CHAT_ID, \"caption\": \"Snapshot of detected activity\"}, files={\"photo\": photo})\n",
    "\n",
    "# === START INFERENCE LOOP ===\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, imgsz=512)\n",
    "    boxes = results[0].boxes\n",
    "    classes = boxes.cls\n",
    "    scores = boxes.conf\n",
    "\n",
    "    for cls_id, conf in zip(classes, scores):\n",
    "        class_name = model.names[int(cls_id)]\n",
    "        if class_name in SUSPICIOUS_CLASSES and conf > CONFIDENCE_THRESHOLD:\n",
    "            # Draw box for visualization (optional)\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Save frame as image\n",
    "            image_path = \"alert.jpg\"\n",
    "            cv2.imwrite(image_path, annotated_frame)\n",
    "\n",
    "            # Send alert\n",
    "            send_telegram_alert(image_path, class_name)\n",
    "\n",
    "            print(f\"🚨 ALERT: {class_name} detected with confidence {conf:.2f}\")\n",
    "            break  # Alert once per suspicious frame to avoid spam\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb272fd0-e422-456f-870c-a21bdfe9ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
